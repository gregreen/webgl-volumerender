<!doctype html>
<html>
<head>
  <title>WebGL Volume Renderer</title>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <link href="volumerender.css" rel="stylesheet" type="text/css"/>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
  <script src="volumerender.js" type="text/javascript"> </script>
</head>
<body>
  <h4>WebGL Volume Renderer</h4>
  <canvas id="gl-canvas" width="480" height="240">
    Your browser does not seem to support the HTML5 <code>&lt;canvas&gt;</code> element.
  </canvas>
  <p><span id="fps"></span><span> frames / second</span></p>
  <script type="x-shader/x-vertex" id="vertex-shader">
    //#version 100
    attribute vec2 position;

    void main() {
      gl_Position = vec4(position, 0.0, 1.0);
    }
  </script>
  <script type="x-shader/x-fragment" id="fragment-shader">
    //#version 100
    precision mediump float;
    uniform vec2 canvasSize;
    uniform sampler2D uSampler[8];
    uniform float time;
    uniform vec3 cameraOrigin;
    uniform mat4 cameraRot;

    #define pi 3.14159
    #define fov 0.50*pi  // Field-of-view of camera
    #define n_steps 100 // # of steps to take for each ray
    #define ray_max_dist 5.0 // Maximum distance for ray
    #define tau_max 4.0 // Truncate ray after reaching this optical depth
    #define xi 12.5 // Overall density scaling

    float step_size = (ray_max_dist / float(n_steps));
    float s_max = tau_max / step_size;
    float screen_dist = 1. / sin(0.5*fov);

    vec3 unit_ray(vec2 uv) {
    	return normalize(vec3(uv, screen_dist));
    }

    float rand(vec2 co){
      return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);
    }

    vec3 xyz2tpr(vec3 xyz) {
      float r = length(xyz);
      return vec3(acos(xyz[2]/r), atan(xyz[1], xyz[0]), r);
    }

    float map_density_val(float v) {
      return v*v*v*v;
    }

    float density(vec3 xyz) {
      vec3 tpr = xyz2tpr(xyz);  // Convert to spherical coords

      if(tpr[2] < 63.096) {
        // Convert to texture (u,v) coords
        vec2 uv = vec2(tpr[1]/(2.*pi), tpr[0]/pi);

        // Determine which texture/channel to load
        // based on distance from origin.
        // Go from outside to inside, b/c largest
        // radii cover most volume.
        // TODO: Rewrite this as a binary search tree.
        if(tpr[2] > 50.12) {
          vec4 img = texture2D(uSampler[7], uv);
          return img[2];
        } else if (tpr[2] > 39.81) {
          vec4 img = texture2D(uSampler[7], uv);
          return img[1];
        } else if (tpr[2] > 31.62) {
          vec4 img = texture2D(uSampler[7], uv);
          return img[0];
        } else if (tpr[2] > 25.12) {
          vec4 img = texture2D(uSampler[6], uv);
          return img[3];
        } else if (tpr[2] > 19.95) {
          vec4 img = texture2D(uSampler[6], uv);
          return img[2];
        } else if (tpr[2] > 15.85) {
          vec4 img = texture2D(uSampler[6], uv);
          return img[1];
        } else if (tpr[2] > 12.59) {
          vec4 img = texture2D(uSampler[6], uv);
          return img[0];
        } else if (tpr[2] > 10.00) {
          vec4 img = texture2D(uSampler[5], uv);
          return img[3];
        } else if (tpr[2] > 7.94) {
          vec4 img = texture2D(uSampler[5], uv);
          return img[2];
        } else if (tpr[2] > 6.31) {
          vec4 img = texture2D(uSampler[5], uv);
          return img[1];
        } else if (tpr[2] > 5.01) {
          vec4 img = texture2D(uSampler[5], uv);
          return img[0];
        } else if (tpr[2] > 3.98) {
          vec4 img = texture2D(uSampler[4], uv);
          return img[3];
        } else if (tpr[2] > 3.16) {
          vec4 img = texture2D(uSampler[4], uv);
          return img[2];
        } else if (tpr[2] > 2.51) {
          vec4 img = texture2D(uSampler[4], uv);
          return img[1];
        } else if (tpr[2] > 2.00) {
          vec4 img = texture2D(uSampler[4], uv);
          return img[0];
        } else if (tpr[2] > 1.58) {
          vec4 img = texture2D(uSampler[3], uv);
          return img[3];
        } else if (tpr[2] > 1.26) {
          vec4 img = texture2D(uSampler[3], uv);
          return img[2];
        } else if (tpr[2] > 1.00) {
          vec4 img = texture2D(uSampler[3], uv);
          return img[1];
        } else if (tpr[2] > 0.794) {
          vec4 img = texture2D(uSampler[3], uv);
          return img[0];
        } else if (tpr[2] > 0.631) {
          vec4 img = texture2D(uSampler[2], uv);
          return img[3];
        } else if (tpr[2] > 0.501) {
          vec4 img = texture2D(uSampler[2], uv);
          return img[2];
        } else if (tpr[2] > 0.398) {
          vec4 img = texture2D(uSampler[2], uv);
          return img[1];
        } else if (tpr[2] > 0.316) {
          vec4 img = texture2D(uSampler[2], uv);
          return img[0];
        } else if (tpr[2] > 0.251) {
          vec4 img = texture2D(uSampler[1], uv);
          return img[3];
        } else if (tpr[2] > 0.200) {
          vec4 img = texture2D(uSampler[1], uv);
          return img[2];
        }
        if (tpr[2] > 0.158) {
          vec4 img = texture2D(uSampler[1], uv);
          return img[1];
        } else if (tpr[2] > 0.126) {
          vec4 img = texture2D(uSampler[1], uv);
          return img[0];
        } else if (tpr[2] > 0.100) {
          vec4 img = texture2D(uSampler[0], uv);
          return img[3];
        } else if (tpr[2] > 0.079) {
          vec4 img = texture2D(uSampler[0], uv);
          return img[2];
        } else if (tpr[2] > 0.063) {
          vec4 img = texture2D(uSampler[0], uv);
          return img[1];
        } else {
          vec4 img = texture2D(uSampler[0], uv);
          return img[0];
        }
      } else {
        return 0.;
      }
    }

    float integrate_ray(vec3 x0, vec3 dx) {
      float s = 0.;
      vec2 dxy = vec2(dx.x, dx.y);
      vec3 x = x0 + dx * rand(dxy);

      for(int k=0; k<n_steps; k++) {
        x += dx;
        s += map_density_val(density(x));

        // Truncate ray after reaching some large optical depth
        if(xi*s > s_max) { break; }
      }

      return xi*s;
    }

    void main() {
      vec2 xy_raw = vec2(gl_FragCoord.x, gl_FragCoord.y);

      // Add a sub-pixel shift to the screen pixel location (to avoid aliasing)
      vec2 offset = vec2(rand(xy_raw), rand(xy_raw));
      vec2 screen_xy = xy_raw + offset;

      // Map screen (x,y) to standard rectangle:
      //   * Long axis goes from -1 to 1
      //   * Short axis has correct aspect ratio
      float mx = max(canvasSize[0], canvasSize[1]);
      vec2 uv = 2. * vec2(screen_xy.x-0.5*canvasSize[0], screen_xy.y-0.5*canvasSize[1]) / mx;

      // Camera ray direction (i.e., projection)
      vec4 dx4 = vec4(unit_ray(uv), 1.);
      dx4 = cameraRot * dx4;
      vec3 dx = step_size * vec3(dx4[0], dx4[1], dx4[2]);

      // Integrate to get optical depth
      float tau = step_size * integrate_ray(cameraOrigin, dx);

      // Convert optical depth to opacity
  	  float opacity = 1. - exp(-tau);

      gl_FragColor = vec4(opacity, opacity, opacity, 1.0);
      //gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0);
      //gl_FragColor = texture2D(uSampler[0], uv);
    }
  </script>
</body>
</html>
