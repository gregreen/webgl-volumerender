<!doctype html>
<html>
<head>
  <title>WebGL Volume Renderer</title>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <link href="volumerender.css" rel="stylesheet" type="text/css"/>
  <script src="volumerender.js" type="text/javascript"> </script>
</head>
<body>
  <p>WebGL Volume Render</p>
  <canvas id="gl-canvas" width="480" height="240">
    Your browser does not seem to support the HTML5 <code>&lt;canvas&gt;</code> element.
  </canvas>
  <script type="x-shader/x-vertex" id="vertex-shader">
    //#version 100
    attribute vec2 position;

    void main() {
      gl_Position = vec4(position, 0.0, 1.0);
    }
  </script>
  <script type="x-shader/x-fragment" id="fragment-shader">
    //#version 100
    precision mediump float;
    uniform vec2 canvasSize;
    uniform sampler2D uSampler;
    uniform float time;
    uniform vec3 cameraOrigin;
    uniform mat4 cameraRot;

    #define pi 3.14159
    #define fov 0.5*pi  // Field-of-view of camera
    #define n_steps 100 // # of steps to take for each ray
    #define ray_max_dist 12.0 // Maximum distance for ray
    #define tau_max 4.0 // Truncate ray after reaching this optical depth

    float step_size = (ray_max_dist / float(n_steps));
    float s_max = tau_max / step_size;
    float screen_dist = 1. / sin(0.5*fov);

    vec3 unit_ray(vec2 uv) {
    	return normalize(vec3(uv, screen_dist));
    }

    float rand(vec2 co){
      return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);
    }

    float density(vec3 xyz) {
      return exp(-0.5 * dot(xyz, xyz));
    }

    vec3 xyz2tpr(vec3 xyz) {
      float r = length(xyz);
      return vec3(acos(xyz[2]/r), atan(xyz[1], xyz[0]), r);
    }

    float density2(vec3 xyz) {
      vec3 tpr = xyz2tpr(xyz);

      if((tpr[2] > 0.8) && (tpr[2] < 1.0)) {
        float xi = 5.;
        vec2 uv = vec2(tpr[1]/(2.*pi), tpr[0]/pi);
        if(tpr[2] < 1.0) {
          vec4 img = 0.5*texture2D(uSampler, uv);
          vec3 img3 = vec3(img.x, img.y, img.z);
          return xi*length(img3);
        }
      } else {
        return 0.;
      }
    }

    float integrate_ray(vec3 x0, vec3 dx) {
      float s = 0.;
      vec2 dxy = vec2(dx.x, dx.y);
      vec3 x = x0 + dx * (rand(dxy)-0.5);

      for(int k=0; k<n_steps; k++) {
        x += dx;
       	s += density2(x);
        if(s > s_max) { break; }  // Truncate ray after reaching some large optical depth
      }

      return s;
    }

    void main() {
      vec2 xy_raw = vec2(gl_FragCoord.x, gl_FragCoord.y);

      // Add a sub-pixel shift to the screen pixel location (to avoid aliasing)
      vec2 offset = vec2(rand(xy_raw), rand(xy_raw));
      vec2 screen_xy = xy_raw + offset;

      // Map screen (x,y) to standard rectangle:
      //   * Long axis goes from -1 to 1
      //   * Short axis has correct aspect ratio
      float mx = max(canvasSize[0], canvasSize[1]);
      vec2 uv = 2. * vec2(screen_xy.x-0.5*canvasSize[0], screen_xy.y-0.5*canvasSize[1]) / mx;

      // Camera ray direction (i.e., projection)
      vec4 dx4 = vec4(unit_ray(uv), 1.);
      dx4 = cameraRot * dx4;
      vec3 dx = step_size * vec3(dx4[0], dx4[1], dx4[2]);

      // Integrate to get optical depth
      float tau = step_size * integrate_ray(cameraOrigin, dx);

      // Convert optical depth to opacity
  	  float opacity = 1. - exp(-tau);

      gl_FragColor = vec4(opacity, opacity, opacity, 1.0);
    }
  </script>
</body>
</html>
